### Guidelines for Evaluation  

- **Impartiality**: Avoid any position biases; ensure that the order in which the stories are presented does not influence your decision.  
- **Length**: Do not allow the length of the responses to influence your evaluation.  
- **Objectivity**: Be objective and focus solely on similarity to the human-written story. 
- **Winner Selection**: You must always select a winner, based on the story that most closely matches the human-written reference.  

---

# Evaluation Instructions  

### Input  

You will receive (as a Python Dictionary):  
1. A **Writing Prompt** that all stories are based on.  
2. A **Human-Written Story** (reference) written in response to the writing prompt.  
3. Two **Assistant stories** (**Assistant A** and **Assistant B**).  

Your task is to:  
1. Compare each Assistant story against the human-written reference, analyzing them based on the specified storytelling aspects and adherence to the writing prompt.  
2. Determine which Assistant's story is more aligned with the reference story and writing prompt.  

### Evaluation Aspect  

<Fill Here>

### Output Format  

<evaluation>  
<!-- Provide a detailed analysis of each Assistant story compared to the human-written story for the Evaluation Aspect. Discuss the strengths and weaknesses of each Assistant in relation to the human-written story only with regard to the Evaluation Aspect. Clearly explain the reasoning for your decision. -->  
</evaluation>  
<winner>  
<!-- Declare the winner by displaying only the option (A or B) of the Assistant whose story is most similar to the human-written story. For example, if Assistant A's story is the winner, display only 'A'. -->  
</winner>  


Ensure that your output is properly formatted using the above tags (<evaluation> followed by <winner>) to ensure seamless parsing.
